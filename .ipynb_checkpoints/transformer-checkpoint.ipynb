{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "## Transformer Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./transformer.png\" width=\"800\">\n",
    "\n",
    "* 基于编码器解码器架构来处理序列对\n",
    "* 跟使用注意力的seq2seq不同, Transformer是**纯**基于注意力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./multihead.PNG\" width=\"500\">\n",
    "\n",
    "* 对于同一key, value, query, 希望抽取不同的信息\n",
    "    * 例如短距离关系和长距离关系\n",
    "* 多头注意力使用h个独立的注意力池化\n",
    "    * 合并各个投(head)输出得到最终输出\n",
    "    \n",
    "    \n",
    "* Q, K, V:\n",
    "    * query $\\mathbf{q} \\in \\mathbb{R}^{d_q}$\n",
    "    * key $\\mathbf{k} \\in \\mathbb{R}^{d_k}$\n",
    "    * value $\\mathbf{v} \\in \\mathbb{R}^{d_v}$\n",
    "* 头$i$的可学习参数$\\mathbf{W}_i^{(q)} \\in \\mathbb{R}^{p_q \\times d_q}, \\mathbf{W}_i^{(k)} \\in \\mathbb{R}^{p_k \\times d_k}, \\mathbf{W}_i^{(v)} \\in \\mathbb{R}^{p_v \\times d_v}$\n",
    "  \n",
    "  \n",
    "* 头$i$的输出$\\mathbf{h}_i = f(\\mathbf{W}_i^{(q)}\\mathbf{q}, \\mathbf{W}_i^{(k)}\\mathbf{k}, \\mathbf{W}_i^{(v)}\\mathbf{v}) \\in \\mathbb{R}^{p_v}$\n",
    "\n",
    "\n",
    "* 输出的可学习参数$\\mathbf{W}_o \\in \\mathbb{R}^{p_o \\times hp_v}$\n",
    "\n",
    "\n",
    "* 多头注意力的输出 (把所有$h$ concat)\n",
    "$$\n",
    "\\mathbb{W}_o \n",
    "\\begin{bmatrix}\n",
    "\\mathbf{h}_1\\\\\n",
    "...\\\\\n",
    "\\mathbf{h}_h\n",
    "\\end{bmatrix}\n",
    "\\in \\mathbb{R}^{p_o}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有掩码的多头注意力\n",
    "\n",
    "* 解码器对序列中一个元素输出时, 不应该考虑该元素之后的元素 (autoregressive)\n",
    "* 可以通过掩码来实现\n",
    "    * 也就是计算$\\mathbf{x}_i$输出时, 假装当前序列长度为$i$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于位置的前馈网络 (FFN)\n",
    "* 将输入形状由$(b,n,d)$变换成$(bn,d)$ 因为$n$会变, 和模型无关\n",
    "\n",
    "\n",
    "* 作用两个全连接层\n",
    "\n",
    "\n",
    "* 输出形状由$(bn,d)$变换成$(b,n,d)$\n",
    "\n",
    "\n",
    "* 等价于两层核窗口为1的一维卷积层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 层归一化 (LayerNorm)\n",
    "\n",
    "* 批量归一化(BatchNorm)对每个**特征/通道 (d)**里元素进行归一化\n",
    "    * 不适合序列长度会变的nlp应用 (n会变, 会导致结果不稳定)\n",
    " <img src=\"./batch_layer_norm.PNG\" width=\"500\">\n",
    " \n",
    " \n",
    " \n",
    "* 层归一化对每个**样本 (b)**里的元素进行归一化 (虽然长度还是会变, 至少是单样本)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 信息传递 (Encoder-Decoder Attention)\n",
    "\n",
    "* 编码器中的输出$\\mathbf{y}_1, ..., \\mathbf{y}_n$\n",
    "\n",
    "\n",
    "* 将其作为解码器中第$i$个Transformer块中多头注意力的key和value\n",
    "    * 它的query来自目标序列\n",
    "    \n",
    "    \n",
    "* 意味着编码器和解码器中块的个数和输出维度都是一样的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测\n",
    "* 预测$t+1$个输出时\n",
    "* 解码器中输入前$t$个预测值\n",
    "    * **在自注意力中，前$t$个预测值作为key和value, 第$t$个预测值还作为query**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "* Transformer时一个纯使用注意力的编码器-解码器\n",
    "* 编码器和解码器都有n个transformer blocks\n",
    "* 每个block里使用multi-head (self) attention, feed-forward neural network, and LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ftcnn",
   "language": "python",
   "name": "ftcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
